---
title: 대규모 데이터를 다루기 위한 기초지식
author: 김기현
date: 2024-4-28
category: Chapter 2
layout: post
mermaid: true
---

# 대규모 데이터를 다루는 세 가지 급소

대규모 데이터를 다루는 요렁 중 프로그램을 작성할 때의 요령은 '어떻게 하면 메모리에서 처리할 수 있을까?'이다.
메모리에서 마쳐야 하는 이유는 디스크 seek 횟수가 확장성, 성능에 크게 영향을 주기 때문이다.


그리고 데이터량 증가에 강한 알고리즘을 사용하는 것이다.
예를 들어 탐색을 한다고 할 때 선형 탐색은 O(n)이라는 시간복잡도를 가진다. 하지만 Log Order이라는 알고리즘을 적용하면 훨씬 빠르게 계산을 마칠 수 있다.

* 1000만 건의 레코드를 탐색한다고 가정한다
  * 선형 탐색 : 1000만 번 계싼
  * Log Order 알고리즘 : 수십번



마지막으로는 데이터 압축이나 검색기술과 같은 테크닉이 활용될 수 있다.
데이터를 압축해서 데이터량을 줄일 수 있다면 읽어내는 seek 횟수도 적어지기 때문에 디스크 읽는 횟수를 최소화할 수 있다는 것이다.
또한 메모리 캐싱이 쉬워진다.

> #### TIP
> 검색이 왜 중요하냐면 특정 용도에 특화된 검색엔진 등을 만들어서 해당 검색 시스템을 웹 애플리케이션에서 이용하는 형태로 전환한다면 속도를 제대로 확보할 수 있기 때문이다.
{: .block-tip}


> #### Memo
> 어떻게 하면 메모리에서 처리를 마칠 수 있을까?
> * 디스크 seek 횟수 최소화하기
> * 국소성을 활용한 분산 실현
> 
> 데이터량 증가에 강한 알고리즘, 데이터 구조
> * 선형검색 < 이분검색
> * O(n) -> O($log_n$)
> 
> 데이터 압축, 정보검색기술
{: .block-warning }